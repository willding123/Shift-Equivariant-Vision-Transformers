JOB_NAME="swin_020307"
#!/bin/bash
# bash script for single node gpu training 
#SBATCH --account=scavenger
#SBATCH --partition=scavenger
#SBATCH --qos=scavenger
#SBATCH --nodes=2
#SBATCH --ntasks-per-node=4
#SBATCH --gpus-per-task=1
#SBATCH --time=2-00:00:00  
#SBATCH --job-name=$JOB_NAME
#SBATCH --output=$JOB_NAME.out
#SBATCH --error=$JOB_NAME.err
##SBATCH --cpus-per-task=32
#SBATCH --mem=128
#SBATCH --mail-type=ALL
#SBATCH --mail-user=pding@umd.edu
nodes=($(scontrol show hostnames $SLURM_JOB_NODELIST))
node_array=($nodes)
head_node=${node_array[0]}
head_node_ip=$(srun --nodes=1 --ntasks=1 -w "$head_node" hostname --ip-address)

module load cuda/11.3.1   
source ~/miniconda3/bin/activate
conda activate swin 
cd /fs/nexus-projects/shift-equivariant_vision_transformer/Swin-Transformer
nvidia-smi
torchrun --nnodes 8 --nproc_per_node 1 rdzv_id=12345 --rdzv_backend=c10d --rdzv_endpoint=$head_node_ip-ip:29500  main.py --cfg configs/swin/poly_swin_tiny_0203.yaml --data-path /fs/cml-datasets/ImageNet/ILSVRC2012 --batch-size 128 --output /fs/nexus-projects/shift-equivariant_vision_transformer --fused_window_process 

# torchrun  --nproc_per_node 8  main.py --cfg configs/swin/poly_swin_tiny_0203.yaml --data-path /fs/cml-datasets/ImageNet/ILSVRC2012 --batch-size 512 --output /fs/nexus-projects/shift-equivariant_vision_transformer --fused_window_process 
